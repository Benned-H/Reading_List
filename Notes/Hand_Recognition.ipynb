{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand Recognition",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LoZGkQTy-HrW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benned-H/Reading_List/blob/master/Notes/Hand_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w_xFBGE0iF_",
        "colab_type": "text"
      },
      "source": [
        "# Hand Segmentation Using Skin Color and Background Information\n",
        "By Wei Wang, Jing Pan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svqbo61i1Bbg",
        "colab_type": "text"
      },
      "source": [
        "This paper presents a new method for segmenting hands from the background of an image. Their method uses an adaptive skin color model with three steps:\n",
        "1. Capture pixel values of hand and background\n",
        "2. Propose Gaussian models on the color space\n",
        "3. Segment the image using various models, intersect the results\n",
        "\n",
        "Results were better than other skin-color-only models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0XNO_C11xaW",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgkU6w3N1yeE",
        "colab_type": "text"
      },
      "source": [
        "Various applications make accurate hand quite important, and segmentation is a crucial first step in this process. Because human skin is generally within a limited range of hues, color-based hand recognition has been investigated for decades. The process depends on two choices: the **color space** and the **model of distribution** for skin colors. Prior work used a variety of techniques and spaces, including:\n",
        "* Color spaces: Normalized RGB, CIE, XYZ, HSV, HSI, YCbCr\n",
        "* Gaussian model for distributions\n",
        "* Edge detection\n",
        "* Varied chrominance spaces\n",
        "* Skin/edge information in various spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63PWGpyE4IDM",
        "colab_type": "text"
      },
      "source": [
        "## 2. Color Space and Gaussian model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqhkQsuQ4N_D",
        "colab_type": "text"
      },
      "source": [
        "Their method was primarily concerned with the use of background information to help segmentation. Thus they only used the normalized RGB and YCbCr color spaces and a single Gaussian model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_0v0skX4oPk",
        "colab_type": "text"
      },
      "source": [
        "**Normalized RGB**   \n",
        "RGB is a convenient color model widely used for processing image data. Unfortunately, the RGB color space is not robust because it cannot define the same color in different conditions or illumination. Normalized RGB was proposed to help this problem, and indeed gets better performance under different light conditions *only in uniform illumination*. Normalized RGB can be calculated as:\n",
        "\n",
        "$R=\\frac{R}{R+G+B}$; $G=\\frac{G}{R+G+B}$; $B=\\frac{B}{R+G+B}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ModQqCxF5_MK",
        "colab_type": "text"
      },
      "source": [
        "**YCbCr**   \n",
        "YCbCr is considered to be better for our purposes than RGB. The clustering is better, it's easy to calculate, and has far less overlap between skin and non-skin tones in various illumination conditions. YCbCr separates out a luminance signal (Y) and two chrominance components (Cb and Cr). We can discard signal Y to improve performance over various lighting conditions. The transform from RGB to YCbCr is simple:\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "Y \\\\ Cb \\\\ Cr\n",
        "\\end{bmatrix}=\n",
        "\\begin{bmatrix}\n",
        "0.2568 & 0.5041 & 0.0979 \\\\\n",
        "-0.1482 & -0.2910 & 0.4392 \\\\\n",
        "0.4392 & -0.3678 & -0.0714\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "R \\\\ G \\\\ B\n",
        "\\end{bmatrix}+\n",
        "\\begin{bmatrix}\n",
        "16 \\\\ 128 \\\\ 128\n",
        "\\end{bmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoZGkQTy-HrW",
        "colab_type": "text"
      },
      "source": [
        "## Gaussian Mixture Model - [Brilliant](https://brilliant.org/wiki/gaussian-mixture-model/#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfWB9RygQ3vC",
        "colab_type": "text"
      },
      "source": [
        "Gaussian mixture models (GMMs) are a probabilistic model for representing normally distributed subpopulations within an overall population (a normal distribution has mean = median = mode, and symmetry over its center). Mixture models don't need to know which subpopulation each data point belongs to, which make them somewhat unsupervised learning (e.g. human height data would have two normal distributions between the sexes, which a GMM could capture)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKghJ421SXjP",
        "colab_type": "text"
      },
      "source": [
        "**Motivation**   \n",
        "We might want to try modeling data with a GMM if it appears to have more than one 'peak' distribution. Unimodal (one 'peak') models would give a poor fit in such a case, and yet GMMs retain the computational benefits of a single Gaussian model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uInoVjDWUPft",
        "colab_type": "text"
      },
      "source": [
        "**To be continued upon additional probability background...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lumBg1GU2Jj",
        "colab_type": "text"
      },
      "source": [
        "## 2 cont."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eQ9fjriU3pn",
        "colab_type": "text"
      },
      "source": [
        "The properties of skin color can be modeled using a Gaussian distribution, which has the formula:   \n",
        "$f(x)=\\frac{1}{\\sqrt{2\\pi \\sigma ^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$, where $\\mu$ is the mean value of the samples and $\\sigma$ is the variance value.\n",
        "\n",
        "Using this model for skin color is a process of matching each pixel in the image. If matched, we consider the pixel as a skin pixel, and if not we consider it background. The two parameters ($\\mu$ and $\\sigma$) decide the structure of our Gaussian model, and need to be learned. A common method for this is **offline training** on thousands of images, but these authors use an adaptive skin color model, which uses the center of the hand skin to calculate and constantly update the parameters of the model. This **online** model seems to work better in different illuminations. Because this paper doesn't explain that model, I'll read through the source of this idea:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37MCrtPLtt5Z",
        "colab_type": "text"
      },
      "source": [
        "# A New Method for Hand Segmentation Using Free-Form Skin Color Model\n",
        "By Ahmad Yahya Dawod, Junaidi Abdullah, and Md.Jahangir Alam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQhQnCYjt43Z",
        "colab_type": "text"
      },
      "source": [
        "Segmentation remains difficult; this paper proposes a new method using a free-form skin color model. The pixel values of the hand are represented in the YbCbCr color space, and the CbCr space is mapped to a CbCr plane. To cluster the region of skin color on this plane, edge detection is used (as opposed to an ellipse) to construct a free-form skin color model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ2gqHmXu5MK",
        "colab_type": "text"
      },
      "source": [
        "## I. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFkIMhequ6Lk",
        "colab_type": "text"
      },
      "source": [
        "The goal of hand segmentation is to detect the position and orientation of hands in an image; the aim of skin color pixel classification is to determine if a color pixel is a skin color or non-skin color. There are several techniques used to model the skin color:\n",
        "* An elliptical boundary model which fits an ellipse on the CbCr plane. The ellipse ends up including non-skin pixel colors, unfortunately.\n",
        "* Coarse model - Fixed straight lines are used as boundaries to a coarse region, but again this includes non-skin pixels.\n",
        "* Estimate the boundary by constructing bilinear and bicubic boxes around the CbCr pixel cluster. Same issue.\n",
        "\n",
        "This paper proposes a new method that uses a free-form boundary which models the skin color depending on the person and minimizes the inclusion of non-skin pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3MbdIsWwob9",
        "colab_type": "text"
      },
      "source": [
        "## II. Suggested Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQQC4xgawtV9",
        "colab_type": "text"
      },
      "source": [
        "Their method consists of four modules:\n",
        "1. Image acquisition (skin region cropping)\n",
        "2. Mapping (CbCr color space mapping)\n",
        "3. Morphology (erosion & dilation)\n",
        "4. Boundary creation (detecting edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQPF2yfhxKeg",
        "colab_type": "text"
      },
      "source": [
        "**Image Acquisition**   \n",
        "Because different people have different skin tones, the authors believe (and I agree) that we shouldn't just define some general range for skin tones. Thus we need to crop a skin image of the person using the system to develop a free-form model specific to them. As has been mentioned, choosing the right color space is the first step we need to tackle. Long story short, we choose YCbCr for the previously written reasons (taken from here, by the way). Skin image cropping just crops the image so we only see a patch of the user's skin as the cropped result. We can then form a cluster in our color space with this example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Nfm5TiynPy",
        "colab_type": "text"
      },
      "source": [
        "**CbCr Color Space Mapping**   \n",
        "They observed that the intensity value Y of YCbCr has little influence on the color distribution. On the Cb and Cr plane, we can generate a map where white (255) points are skin pixels and black (0) are non-skin. The resulting 255x255 map is the range of skin color present in the cropped image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-894vL3zqU0",
        "colab_type": "text"
      },
      "source": [
        "**Morphology**   \n",
        "This stage uses image processing to create a cleaner single free-form shape. Two operations are used: Dilation adds pixels to fill in missing pixels in the white cluster and erosion removes extra pixels not belonging to the white cluster. Both help our resulting segmentation, and are applied in the order of dilation, erosion, and then edge point extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3jnx4A_1rYK",
        "colab_type": "text"
      },
      "source": [
        "**Boundary Creation**   \n",
        "Here we determine the actual region which will define skin and non-skin color pixels. We consider the white cluster and apply an edge detection algorithm, for which there are a few different methods (gradient, laplacian). The **gradient method** detects the edge by looking for the maximum and minimum in the first derivative of the image, whereas the **laplacian method** searches for zero crossings in the second derivative of the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL5kUyZz3BNm",
        "colab_type": "text"
      },
      "source": [
        "For gradient edge detection, given image function $f(x,y)$, the gradient magnitude $g(x,y)$ and direction $\\theta(x,y)$ are computed as:   \n",
        "$g(x,y)\\cong \\sqrt{\\Delta x^2 + \\Delta y^2}$ and $\\theta(x,y)\\cong a \\tan(\\frac{\\Delta y}{\\Delta x})$, where $\\Delta x =f(x+n,y)-f(x-n,y)$ and $\\Delta y =f(x,y+n)-f(x,y-n)$, where $n$ is a small integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB0o2QQH42BF",
        "colab_type": "text"
      },
      "source": [
        "To be continued...   \n",
        "*--Last revised 6/22/2019--*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAd-766T-ngj",
        "colab_type": "text"
      },
      "source": [
        "# To Read:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbiBJ7NV-pN5",
        "colab_type": "text"
      },
      "source": [
        "* https://wolfcrow.com/understanding-luminance-and-chrominance/\n",
        "* https://homepages.inf.ed.ac.uk/rbf/HIPR2/dilate.htm\n",
        "* https://homepages.inf.ed.ac.uk/rbf/HIPR2/erode.htm\n",
        "* Finish the first paper"
      ]
    }
  ]
}